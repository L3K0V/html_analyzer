{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation Recognition\n",
    "\n",
    "The idea is on given element from the DOM tree of a webpage to determine if this particular element is the main navigation of the page. By main navigation we define the only one navigation with the main section or category links. Every page has a main navigation and can contains multiple menus, context navigations and so on. We are trying to determine onlt the main navigation.\n",
    "\n",
    "## Linear regression statistic model\n",
    "\n",
    "Using weights on element DOM information we calculate probability. After that we build a linear model from the element based on accessibility roles, HTML tag, class names, ids and other components that we will cover later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"sklearn\", message=\"^Objective did not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"linear-regression-input.csv\", header=0)\n",
    "df = df.drop_duplicates(subset=['url', 'tag', 'class', 'class_count', 'id', 'role', 'home', 'depth', 'links', 'links_by_depth'], keep='first')\n",
    "\n",
    "Y = df['probability']\n",
    "X = df[['tag', 'class', 'id', 'role', 'home', 'depth', 'links', 'links_by_depth']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the model\n",
    "\n",
    "The linear model of every element is based on several criteria\n",
    "\n",
    "### HTML tag\n",
    "\n",
    "| tag    \t| weight    | comment \t|\n",
    "| --------\t| --------\t| ---------\t|\n",
    "| `nav`   \t| **3**    \t| we are sure that this element holds some navigation \t|\n",
    "| `div`    \t| **2**    \t| they are many containers holding the navigation itself \t|\n",
    "| `header` \t| **1**    \t| it is common to have navigation in the header \t|\n",
    "| other  \t| **0**    \t| we are neutral here, cannot tell \t|\n",
    "| `footer` \t| **-1**   \t| if it is footer, we really don't care of it \t|\n",
    "\n",
    "### Element classes and ids\n",
    "\n",
    "| weight \t| keywords            \t| comment                                                                               \t|\n",
    "|--------\t|---------------------\t|---------------------------------------------------------------------------------------\t|\n",
    "| **2**  \t| `navigation`, `nav` \t| we assume that this can be navigation or container for sure if these keywords appears \t|\n",
    "| **1**  \t| `menu`, `main`      \t| we are not sure if this can be main navigation but could be in some corner cases      \t|\n",
    "| **-1** \t| `footer`            \t| keywords indicating that we are not interested in this element for sure               \t|\n",
    "\n",
    "### Accessibility roles\n",
    "\n",
    "| role                         \t| priority \t| comment                                          \t|\n",
    "|------------------------------\t|----------\t|--------------------------------------------------\t|\n",
    "| `navigation`                 \t| **high** \t| for sure this is the main navigation on the page \t|\n",
    "| `menu`, `menubar`, `toolbar` \t| medium   \t| menus, context covigations and etc in most cases  |\n",
    "| `contentinfo`                \t| low      \t| common used for the footer                       \t|\n",
    "\n",
    "### Other\n",
    "- `depth` - Depth of the element in the DOM tree\n",
    "- `home` - Whatever if element has links and some of them points to the home ('/')\n",
    "- `links` - if the element contains links\n",
    "- `links_by_depth` - if more than half of the links are at same depth on the DOM tree\n",
    "\n",
    "## Probability\n",
    "We calculate some probability using weights on the same criteria for every element. Using this probability we try to find a successful rate of the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)  \n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients\n",
    "\n",
    "Using our data set lets examine that are the coefficient that every criteria participates. For example you will se that `depth` coefficient is negative, but if we train the model without it the score drop with 0.01% This leads me to the conclustion that element deeper in the DOM tree are less possible to be navigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <td>0.054247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0.192798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.073258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>role</th>\n",
       "      <td>0.268792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0.354699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <td>-0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links</th>\n",
       "      <td>0.073681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links_by_depth</th>\n",
       "      <td>0.197675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Coefficient\n",
       "tag                0.054247\n",
       "class              0.192798\n",
       "id                 0.073258\n",
       "role               0.268792\n",
       "home               0.354699\n",
       "depth             -0.001822\n",
       "links              0.073681\n",
       "links_by_depth     0.197675"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score of the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337631753170562"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.158407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.433435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.488262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.419673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.154161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.153481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.156538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.161127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.433435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.240996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.164185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.430377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.433435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.422222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.439722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.165883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.164014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.154669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.167072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.167072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.434115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.243001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.435984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.427149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.362060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.424771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.155858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.160276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.492509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.550249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.782903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.161465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.164014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.579244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.424091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.05</td>\n",
       "      <td>0.873137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.156538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.162316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.778062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.025026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.425451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.486902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.431566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.159087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.437173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.160276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.157218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.167752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>1.40</td>\n",
       "      <td>1.328709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.432246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.434795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.159596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.156538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.160956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.489451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.085693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.168432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.429697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.026215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.165203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "2840    0.15   0.158407\n",
       "311     0.40   0.433435\n",
       "301     0.60   0.488262\n",
       "18      0.40   0.419673\n",
       "1925    0.15   0.154161\n",
       "239     0.15   0.153481\n",
       "1439    0.15   0.156538\n",
       "2540    0.15   0.161127\n",
       "1588    0.40   0.433435\n",
       "1036    0.25   0.240996\n",
       "57      0.15   0.164185\n",
       "1975    0.40   0.430377\n",
       "1265    0.40   0.433435\n",
       "2545    0.40   0.422222\n",
       "3036    0.40   0.439722\n",
       "1029    0.15   0.165883\n",
       "414     0.15   0.164014\n",
       "95      0.15   0.154669\n",
       "1816    0.15   0.167072\n",
       "1512    0.15   0.167072\n",
       "1670    0.40   0.434115\n",
       "2521    0.25   0.243001\n",
       "411     0.40   0.435984\n",
       "1476    0.40   0.427149\n",
       "50      0.40   0.362060\n",
       "2583    0.40   0.424771\n",
       "1147    0.15   0.155858\n",
       "3046    0.15   0.160276\n",
       "212     0.60   0.492509\n",
       "1837    0.60   0.550249\n",
       "...      ...        ...\n",
       "1856    0.75   0.782903\n",
       "68      0.15   0.161465\n",
       "1808    0.15   0.164014\n",
       "1235    0.60   0.579244\n",
       "1931    0.40   0.424091\n",
       "209     1.05   0.873137\n",
       "2497    0.15   0.156538\n",
       "1341    0.15   0.162316\n",
       "1798    0.25   0.778062\n",
       "287     0.15  -0.025026\n",
       "2026    0.40   0.425451\n",
       "1309    0.60   0.486902\n",
       "237     0.40   0.431566\n",
       "1344    0.15   0.159087\n",
       "227     0.40   0.437173\n",
       "1159    0.15   0.160276\n",
       "1590    0.15   0.157218\n",
       "1296    0.15   0.167752\n",
       "1847    1.40   1.328709\n",
       "1597    0.40   0.432246\n",
       "1514    0.40   0.434795\n",
       "3082    0.15   0.159596\n",
       "1139    0.15   0.156538\n",
       "1077    0.15   0.160956\n",
       "1725    0.60   0.489451\n",
       "403     0.25   0.085693\n",
       "1011    0.15   0.168432\n",
       "1433    0.40   0.429697\n",
       "3249    0.15  -0.026215\n",
       "66      0.15   0.165203\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) \n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.044615374107410344\n",
      "Mean Squared Error: 0.006399412940528507\n",
      "Root Mean Squared Error: 0.07999633079415897\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Using https://www.rheinische-anzeigenblaetter.de/ our library recognized successfully the page header, footer and navigation with the following internal probability recognized as the main navigation:\n",
    "\n",
    "- `navigation` (1.4) with model `\"3,2,0,0,1,4,1,1\"`\n",
    "- `header` (0.6) with model `\"1,0,0,0,1,3,1,1\"`\n",
    "- `footer` (0.25) with model `\"-1,-1,0,0,0,3,1,1\"`\n",
    "\n",
    "Now lets check how our linear regression will score with these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,8) and (9,) not aligned: 8 (dim 1) != 9 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7d0107bd0265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 241\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ml/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,8) and (9,) not aligned: 8 (dim 1) != 9 (dim 0)"
     ]
    }
   ],
   "source": [
    "array = np.array([[3,2,0,0,1,4,1,1], [1,0,0,0,1,3,1,1], [-1,-1,0,0,0,3,1,1]])\n",
    "model.predict(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "As we see the linear regression model predicts on random data pretty nice. We can assume from the results that the navigation is inside the header. Our library also confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
